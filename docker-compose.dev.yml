services:
  # SnapDog2 application - container-only development with full debugging
  app:
    build:
      context: .
      dockerfile: ./Dockerfile
      target: development # Multi-stage development target
    volumes:
      - .:/app:cached # Mount source code for hot reload
      - ~/.nuget/packages:/home/vscode/.nuget/packages:cached # NuGet cache
      - ~/.nuget/local:/app/local-nuget:cached # Local NuGet packages for development
    env_file:
      - ./devcontainer/.env
    environment:
      - DOTNET_ENVIRONMENT=Development
      - DOTNET_USE_POLLING_FILE_WATCHER=true
      - DOTNET_WATCH_RESTART_ON_RUDE_EDIT=true
    depends_on:
      - snapcast-server
      - mqtt
      - navidrome
    networks:
      snapdog-dev:
        ipv4_address: 172.20.0.2
    # Enable debugger
    stdin_open: true
    tty: true

  # Caddy reverse proxy with dashboard - SINGLE PORT TO HOST
  caddy:
    image: caddy:2-alpine
    ports:
      - "8000:80" # Only exposed port!
    volumes:
      - ./devcontainer/caddy/Caddyfile:/etc/caddy/Caddyfile:ro
      - ./devcontainer/caddy/site:/srv:ro
      - caddy_data:/data
      - caddy_config:/config
    depends_on:
      - app
      - snapcast-server
      - snapcast-client-living-room
      - snapcast-client-kitchen
      - snapcast-client-bedroom
      - navidrome
      - jaeger
    networks:
      snapdog-dev:
        ipv4_address: 172.20.0.4
    restart: unless-stopped

  # Snapcast Server - NO HOST PORTS
  snapcast-server:
    build:
      context: ./devcontainer/snapcast-server
    hostname: snapcast-server
    env_file:
      - ./devcontainer/.env
    ports:
      - "1705:1705" # Snapcast server port
    networks:
      snapdog-dev:
        ipv4_address: 172.20.0.5
    restart: unless-stopped

  # Living room client
  snapcast-client-living-room:
    build:
      context: ./devcontainer/snapcast-client
    restart: unless-stopped
    depends_on:
      - snapcast-server
    environment:
      - SNAPSERVER_HOST=172.20.0.5 # IP address of snapcast-server
      - CLIENT_ID=living-room
      - FIXED_MAC_ADDRESS=02:42:ac:11:00:10
    networks:
      snapdog-dev:
        ipv4_address: 172.20.0.6
        mac_address: 02:42:ac:11:00:10

  # Kitchen client
  snapcast-client-kitchen:
    build:
      context: ./devcontainer/snapcast-client
    restart: unless-stopped
    depends_on:
      - snapcast-server
    environment:
      - SNAPSERVER_HOST=172.20.0.5
      - CLIENT_ID=kitchen
      - FIXED_MAC_ADDRESS=02:42:ac:11:00:11
    networks:
      snapdog-dev:
        ipv4_address: 172.20.0.7
        mac_address: 02:42:ac:11:00:11

  # Bedroom client
  snapcast-client-bedroom:
    build:
      context: ./devcontainer/snapcast-client
    restart: unless-stopped
    depends_on:
      - snapcast-server
    environment:
      - SNAPSERVER_HOST=172.20.0.5
      - CLIENT_ID=bedroom
      - FIXED_MAC_ADDRESS=02:42:ac:11:00:12
    networks:
      snapdog-dev:
        ipv4_address: 172.20.0.8
        mac_address: 02:42:ac:11:00:12

  # MQTT Broker
  mqtt:
    image: eclipse-mosquitto:2.0
    volumes:
      - ./devcontainer/mosquitto/mosquitto.conf:/mosquitto/config/mosquitto.conf
      - ./devcontainer/mosquitto/passwd:/mosquitto/config/passwd
      - mqtt_data:/mosquitto/data
      - mqtt_logs:/mosquitto/log
    ports:
      - "1883:1883" # MQTT port
    environment:
      - MOSQUITTO_LOG_LEVEL=debug
    command: ["/usr/sbin/mosquitto", "-c", "/mosquitto/config/mosquitto.conf", "-v"]
    networks:
      snapdog-dev:
        ipv4_address: 172.20.0.3
    restart: unless-stopped

  # Navidrome - NO HOST PORTS (via Caddy)
  navidrome:
    image: deluan/navidrome:latest
    environment:
      ND_ENABLEINSIGHTSCOLLECTOR: "false" # Disable insights collector
      ND_SCANSCHEDULE: "1h"
      ND_LOGLEVEL: info
      ND_SESSIONTIMEOUT: "24h"
      ND_MUSICFOLDER: /music
      ND_DATAFOLDER: /data
      ND_BASEURL: "/music" # Configure for reverse proxy
    volumes:
      - ./devcontainer/music:/music:ro
      - navidrome_data:/data
    networks:
      snapdog-dev:
        ipv4_address: 172.20.0.9
    restart: unless-stopped

  # KNX Gateway Simulator - Custom Alpine-based container
  knxd:
    build:
      context: ./devcontainer/knxd
      dockerfile: Dockerfile
    environment:
      - ADDRESS=0.0.1 # KNX daemon address (standard format)
      - CLIENT_ADDRESS=0.0.2:8 # Client address range (start:count)
      - INTERFACE=dummy # Use dummy interface for simulation
      - DEBUG_LEVEL=verbose # Debug level (verbose for troubleshooting)
      - FILTERS=single,pace:queue # Filters with queue to avoid warnings
    ports:
      - "3671:3671/udp" # KNX/IP port
    networks:
      snapdog-dev:
        ipv4_address: 172.20.0.10
    restart: unless-stopped
    # Security: Run as non-root with minimal capabilities
    user: "1000:1000"
    cap_drop:
      - ALL
    cap_add:
      - NET_BIND_SERVICE
    # Health check
    healthcheck:
      test: ["CMD", "netstat", "-ln"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s

  # Jaeger
  jaeger:
    image: jaegertracing/all-in-one:latest
    environment:
      COLLECTOR_OTLP_ENABLED: true
    networks:
      snapdog-dev:
        ipv4_address: 172.20.0.11
    restart: unless-stopped

  # Prometheus for metrics
  prometheus:
    image: prom/prometheus:latest
    volumes:
      - ./devcontainer/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml:ro
    networks:
      snapdog-dev:
        ipv4_address: 172.20.0.12
    profiles: ["monitoring"]
    restart: unless-stopped

  # Grafana for visualization
  grafana:
    image: grafana/grafana:latest
    environment:
      GF_SECURITY_ADMIN_PASSWORD: snapdog-dev
      GF_SERVER_ROOT_URL: http://localhost:8000/grafana/
      GF_SERVER_SERVE_FROM_SUB_PATH: true
    networks:
      snapdog-dev:
        ipv4_address: 172.20.0.13
    profiles: ["monitoring"]
    restart: unless-stopped

  # KNX Monitor - Visual debugging tool for KNX bus activity
  #
  # TROUBLESHOOTING:
  # - If you see "Unrecognized command or argument" errors, use short form arguments (-g, -p, -v)
  # KNX Monitor service has been moved to its own repository
  # See: https://github.com/yourusername/KnxMonitor
    restart: unless-stopped
    # üè• HEALTH CHECK - Enabled by default in Docker containers
    # 
    # The KNX Monitor automatically enables health check service when running in containers.
    # This provides comprehensive monitoring of both application and KNX connection status.
    #
    # Features:
    # - HTTP-based health check using dedicated endpoint
    # - Checks both application process AND KNX connection status
    # - Returns detailed JSON with connection info and message count
    # - More reliable than simple process checks
    # - Faster response time (5s timeout vs 10s)
    # - More frequent checks (15s interval vs 30s)
    # - Longer startup grace period (30s) for KNX connection establishment
    #
    # Endpoints (internal to container):
    # - http://localhost:8080/health: Detailed health information with uptime and message count
    # - http://localhost:8080/ready: Simple readiness check (used by Docker health check)
    #
    # To debug health check: 
    # - docker inspect snapdog-knx-monitor-1 --format='{{.State.Health.Status}}'
    # - docker inspect snapdog-knx-monitor-1 --format='{{range .State.Health.Log}}{{.Output}}{{end}}'
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/ready"]
      interval: 15s
      timeout: 5s
      retries: 5
      start_period: 30s
    labels:
      - "traefik.enable=false" # Not exposed via web interface
      - "com.docker.compose.service=knx-monitor"

volumes:
  mqtt_data:
  mqtt_logs:
  navidrome_data:
  caddy_data:
  caddy_config:
  knx_monitor_nuget:

networks:
  snapdog-dev:
    driver: bridge
    ipam:
      config:
        - subnet: 172.20.0.0/16
